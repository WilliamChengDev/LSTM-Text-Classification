{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15f51930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading database...\n",
      "download complete\n",
      "extracting database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dh/gn6f4p_s3hq57q937fd3gcs80000gn/T/ipykernel_64785/2850731199.py:17: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall(path=\"data\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database extracted\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "if not os.path.exists(\"data/aclImdb_v1.tar.gz\"):\n",
    "        #download database\n",
    "        print(\"downloading database...\")\n",
    "        urllib.request.urlretrieve(\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \"data/aclImdb_v1.tar.gz\")\n",
    "        print(\"download complete\")\n",
    "\n",
    "if not os.path.exists(\"data/aclImdb/\"):\n",
    "        #extract database\n",
    "        print(\"extracting database...\")\n",
    "        with tarfile.open(\"data/aclImdb_v1.tar.gz\", \"r:gz\") as tar:\n",
    "                tar.extractall(path=\"data\")\n",
    "        print(\"database extracted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fa68431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def read_imdb_data(data_dir='data/aclImdb'):\n",
    "    data = {}\n",
    "    labels = {}\n",
    "\n",
    "     # Loop over the two splits: training and testing\n",
    "    for data_type in ['train', 'test']:\n",
    "        data[data_type] = {}\n",
    "        labels[data_type] = {}\n",
    "\n",
    "        # Loop over both sentiment categories: positive and negative\n",
    "        for sentiment in ['pos', 'neg']:\n",
    "            data[data_type][sentiment] = []\n",
    "            labels[data_type][sentiment] = []\n",
    "\n",
    "            # Construct path to all text files of the current split and sentiment\n",
    "            path = os.path.join(data_dir, data_type, sentiment, '*.txt')\n",
    "            files = glob.glob(path)\n",
    "\n",
    "            # Read each review text file\n",
    "            for f in files:\n",
    "                with open(f) as review:\n",
    "                    data[data_type][sentiment].append(review.read())\n",
    "                    # Assign label 1 for 'pos' and 0 for 'neg'\n",
    "                    labels[data_type][sentiment].append(1 if sentiment == 'pos' else 0)\n",
    "\n",
    "            # Sanity check: ensure that every text has a matching label\n",
    "            assert len(data[data_type][sentiment]) == len(labels[data_type][sentiment]), \\\n",
    "                    \"{}/{} data size does not match labels size\".format(data_type, sentiment)\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74031e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDb reviews: train = 12500 pos / 12500 neg, test = 12500 pos / 12500 neg\n"
     ]
    }
   ],
   "source": [
    "data, labels = read_imdb_data()\n",
    "print(\"IMDb reviews: train = {} pos / {} neg, test = {} pos / {} neg\".format(\n",
    "            len(data['train']['pos']), len(data['train']['neg']),\n",
    "            len(data['test']['pos']), len(data['test']['neg'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f38e5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Save the loaded review texts into a JSON file\n",
    "json.dump(data, open('data/data.json', 'w'))\n",
    "# Save the sentiment labels into another JSON file\n",
    "json.dump(labels, open('data/labels.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb500d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and load the movie review data from 'data.json'\n",
    "f=open('data/data.json')\n",
    "data = json.load(f)\n",
    "f.close()\n",
    "\n",
    "# Open and load the sentiment labels from 'labels.json'\n",
    "f=open('data/labels.json')\n",
    "labels = json.load(f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
